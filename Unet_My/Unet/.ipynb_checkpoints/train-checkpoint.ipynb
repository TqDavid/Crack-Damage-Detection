{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load train.py\n",
    "'''\n",
    " * @author [Zizhao Zhang]\n",
    " * @email [zizhao@cise.ufl.edu]\n",
    " * @create date 2017-05-19 03:06:32\n",
    " * @modify date 2017-05-19 03:06:32\n",
    " * @desc [description]\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "SEED=0\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "import os, shutil\n",
    "from model import UNet\n",
    "from utils import dice_coef\n",
    "from loader import dataLoader, folderLoader\n",
    "from utils import VIS, mean_IU\n",
    "# configure args\n",
    "from opts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save and compute metrics\n",
    "vis = VIS(save_path=opt.checkpoint_path)\n",
    "\n",
    "# configuration session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define data loader (with train and test)\n",
    "img_shape = [ opt.imHeight,opt.imWidth]\n",
    "#img_shape = [512, 512]\n",
    "train_generator, train_samples = dataLoader(opt.data_path+'/', opt.batch_size,img_shape)\n",
    "test_generator, test_samples = dataLoader(opt.data_path+'/val/', 1,  img_shape, train_mode=False)\n",
    "# define test loader (optional to replace above test_generator)\n",
    "# test_generator, test_samples = folderLoader(opt.data_path, imSize=(opt.imSize,opt.imSize))\n",
    "opt.iter_epoch = int(train_samples) \n",
    "# define input holders\n",
    "label = tf.placeholder(tf.int32, shape=[None]+img_shape)\n",
    "# define model\n",
    "with tf.name_scope('unet'):\n",
    "    model = UNet().create_model(img_shape=img_shape+[3], num_class=opt.num_class)\n",
    "    img = model.input\n",
    "    pred = model.output\n",
    "# define loss\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=pred))\n",
    "# define optimizer\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "with tf.name_scope('learning_rate'):\n",
    "    learning_rate = tf.train.exponential_decay(opt.learning_rate, global_step,\n",
    "                                           opt.iter_epoch, opt.lr_decay, staircase=True)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy_loss, global_step=global_step)\n",
    "# compute dice score for simple evaluation during training\n",
    "# with tf.name_scope('dice_eval'):\n",
    "#     dice_evaluator = tf.reduce_mean(dice_coef(label, pred))\n",
    "''' Tensorboard visualization '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleanup pervious info\n",
    "if opt.load_from_checkpoint == '':\n",
    "    cf = os.listdir(opt.checkpoint_path)\n",
    "    for item in cf: \n",
    "        if 'event' in item: \n",
    "            os.remove(os.path.join(opt.checkpoint_path, item))\n",
    "# define summary for tensorboard\n",
    "tf.summary.scalar('cross_entropy_loss', cross_entropy_loss)\n",
    "tf.summary.scalar('learning_rate', learning_rate)\n",
    "summary_merged = tf.summary.merge_all()\n",
    "# define saver\n",
    "train_writer = tf.summary.FileWriter(opt.checkpoint_path, sess.graph)\n",
    "saver = tf.train.Saver() # must be added in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Main '''\n",
    "tot_iter = opt.iter_epoch * opt.epoch\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "with sess.as_default():\n",
    "    # restore from a checkpoint if exists\n",
    "    # the name_scope can not change \n",
    "#    if opt.load_from_checkpoint != '':\n",
    "#        try:\n",
    "#            saver.restore(sess, opt.load_from_checkpoint)\n",
    "#            print ('--> load from checkpoint '+opt.load_from_checkpoint)\n",
    "#        except:\n",
    "#            print ('unable to load checkpoint ...' + str(e))\n",
    "#    # debug\n",
    "    start = global_step.eval()\n",
    "    for it in range(start, tot_iter):\n",
    "        if it % opt.iter_epoch == 0 or it == start:\n",
    "            \n",
    "            saver.save(sess, opt.checkpoint_path+'model', global_step=global_step)\n",
    "            print ('save a checkpoint at '+ opt.checkpoint_path+'model-'+str(it))\n",
    "            print ('start testing {} samples...'.format(test_samples))\n",
    "            for ti in range(test_samples):\n",
    "                x_batch, y_batch = next(test_generator)\n",
    "                # tensorflow wants a different tensor order\n",
    "                feed_dict = {   \n",
    "                                img: x_batch,\n",
    "                                label: y_batch,\n",
    "                            }\n",
    "                loss, pred_logits = sess.run([cross_entropy_loss, pred], feed_dict=feed_dict)\n",
    "                pred_map_batch = np.argmax(pred_logits, axis=3)\n",
    "                # import pdb; pdb.set_trace()\n",
    "                for pred_map, y in zip(pred_map_batch, y_batch):\n",
    "                    score = vis.add_sample(pred_map, y)\n",
    "            vis.compute_scores(suffix=it)\n",
    "        \n",
    "        x_batch, y_batch = next(train_generator)\n",
    "        feed_dict = {   img: x_batch,\n",
    "                        label: y_batch\n",
    "                    }\n",
    "        _, loss, summary, lr, pred_logits = sess.run([train_step, \n",
    "                                    cross_entropy_loss, \n",
    "                                    summary_merged,\n",
    "                                    learning_rate,\n",
    "                                    pred\n",
    "                                    ], feed_dict=feed_dict)\n",
    "        global_step.assign(it).eval()\n",
    "\n",
    "        pred_map = np.argmax(pred_logits[0],axis=2)\n",
    "        score, _ = mean_IU(pred_map, y_batch[0])\n",
    "\n",
    "        train_writer.add_summary(summary, it)\n",
    "        if it % 20 == 0 : \n",
    "            print ('[iter %d, epoch %.3f]: lr=%f loss=%f, mean_IU=%f' % (it, float(it)/opt.iter_epoch, lr, loss, score))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
